{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Use data from [phoible](https://phoible.org/) to learn a useful embedding from phonological feature space to a vector space in which distances between allophones tend to be small. Go to the [phoible project github](https://github.com/phoible/dev/tree/master/data) and grab phoible.csv for this exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmbedPhones(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(EmbedPhones, self).__init__()\n",
    "        \n",
    "        self.res = nn.Linear(num_features,num_features,bias=False)\n",
    "#         identity=torch.from_numpy(np.identity(num_features,dtype=np.dtype('float32')))\n",
    "        with torch.no_grad():\n",
    "            self.res.weight.normal_(0,0.02)\n",
    "#             self.embed.weight += identity\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x+self.res(x) # res represents the difference between the embedding map and the identity map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "def add_path_to_local_module(module_name):\n",
    "    module_path = os.path.abspath(os.path.join(module_name))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "add_path_to_local_module(\"epitran\")\n",
    "add_path_to_local_module(\"panphon\")\n",
    "\n",
    "import panphon.featuretable\n",
    "ft = panphon.featuretable.FeatureTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22  features for 'ɛ æ':\n",
      " tensor([[ 1.,  1., -1.,  1., -1., -1., -1.,  0.,  1., -1., -1.,  0., -1.,  0.,\n",
      "         -1., -1., -1., -1., -1., -1., -1., -1.],\n",
      "        [ 1.,  1., -1.,  1., -1., -1., -1.,  0.,  1., -1., -1.,  0., -1.,  0.,\n",
      "         -1., -1.,  1., -1., -1., -1.,  1., -1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9875,  0.9508, -1.0109,  0.8489, -1.0821, -0.9516, -0.9688,  0.0137,\n",
       "          1.0976, -0.9412, -0.9087,  0.1289, -0.9937, -0.1002, -1.0093, -0.9550,\n",
       "         -1.0120, -0.9801, -1.0466, -0.9510, -0.9890, -1.0063],\n",
       "        [ 1.0730,  0.9143, -1.0246,  0.8848, -1.0358, -0.9153, -0.9243, -0.0173,\n",
       "          1.0168, -0.9409, -0.9666,  0.1447, -1.0043, -0.0419, -0.9813, -0.9312,\n",
       "          1.0069, -1.0088, -1.0312, -1.0657,  1.0583, -0.9335]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PanphonNoLikey(Exception):\n",
    "    pass\n",
    "\n",
    "class NoAvailableData(Exception):\n",
    "    pass\n",
    "\n",
    "def to_panphon_fts(ipa_symbols):\n",
    "    \"\"\" Convert a string of ipa symbols to a numpy matrix whose rows are features.\n",
    "        Do not include duplicates when panphon identifies symbols in terms of features. \"\"\"\n",
    "    if ipa_symbols == \"NA\" :  raise NoAvailableData(\"The string you gave indicates that there's no allophone data\")\n",
    "    fts = ft.word_to_vector_list(ipa_symbols,numeric=True)\n",
    "    if not fts : raise PanphonNoLikey(\"Panphon does not recognize this IPA symbol\")\n",
    "    fts = np.array(fts) \n",
    "    fts = np.unique(fts,axis=0) # panphon will identify some things; this gets rid of duplicates\n",
    "    fts = fts.astype(np.dtype('float32'))\n",
    "    return torch.from_numpy(fts)\n",
    "\n",
    "feats = to_panphon_fts('ɛ æ')\n",
    "num_features = len(feats[0])\n",
    "print(num_features,\" features for 'ɛ æ':\\n\",feats)\n",
    "emb = EmbedPhones(num_features)\n",
    "emb(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def allophone_data_by_language(num_lists=np.inf):\n",
    "    f = open('phoible.csv')\n",
    "    reader = csv.reader(f)\n",
    "    head = next(reader)\n",
    "    allophones_index = head.index('Allophones')\n",
    "    langkey_index = head.index('ISO6393')\n",
    "    last_langkey = \"not a lang key\"\n",
    "    num_yielded = 0\n",
    "    for i,row in enumerate(reader):\n",
    "        if row[langkey_index] != last_langkey:\n",
    "#             print(\"About to yield data for language\",last_langkey)\n",
    "            last_langkey = row[langkey_index]\n",
    "            if i!=0 and allophone_data:\n",
    "                yield allophone_data\n",
    "                num_yielded += 1\n",
    "            if num_yielded >= num_lists: break\n",
    "            allophone_data = []\n",
    "        try:\n",
    "            allophone_list = to_panphon_fts(row[allophones_index])\n",
    "        except PanphonNoLikey: # We will just skip the entire list of allophones in this case\n",
    "            continue\n",
    "        except NoAvailableData: # We will just skip the entire list of allophones in this case\n",
    "            continue\n",
    "        allophone_data.append(allophone_list)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allophone_data_by_language_list = list(allophone_data_by_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def allophone_data_by_language_shuffled():\n",
    "    indices = list(range(len(allophone_data_by_language_list)))\n",
    "    random.shuffle(indices)\n",
    "    for index in indices:\n",
    "        yield allophone_data_by_language_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_pairs(N):\n",
    "    \"\"\"Generate pairs of integers i<j such that 0 <= i < j < N\"\"\"\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            yield i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqdist(x,y):\n",
    "    \"\"\"Return squared distance between two 1D torch tensors\"\"\"\n",
    "    return ((x-y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "emb = EmbedPhones(num_features)\n",
    "lr = 0.0001\n",
    "optimizer = optim.Adam(emb.parameters(),lr=lr,weight_decay=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 languages processed. Avg cost:  -1460.8521728515625\n",
      "50 languages processed. Avg cost:  -1503.3360885620118\n",
      "100 languages processed. Avg cost:  -4249.62675415039\n",
      "150 languages processed. Avg cost:  -1321.8668353271485\n",
      "200 languages processed. Avg cost:  -2573.298227844238\n",
      "250 languages processed. Avg cost:  -1988.411904296875\n",
      "300 languages processed. Avg cost:  -1502.9762258911132\n",
      "350 languages processed. Avg cost:  -1612.1276971435548\n",
      "400 languages processed. Avg cost:  -1405.1731420898439\n",
      "450 languages processed. Avg cost:  -3501.915505371094\n",
      "500 languages processed. Avg cost:  -1530.2258169555664\n",
      "550 languages processed. Avg cost:  -1712.7431854248048\n",
      "600 languages processed. Avg cost:  -4124.578305358887\n",
      "650 languages processed. Avg cost:  -1924.862767944336\n",
      "700 languages processed. Avg cost:  -1695.6082055664062\n",
      "750 languages processed. Avg cost:  -1790.1763726806641\n",
      "800 languages processed. Avg cost:  -1780.4346197509765\n",
      "850 languages processed. Avg cost:  -2070.85224609375\n",
      "900 languages processed. Avg cost:  -2257.706412963867\n",
      "950 languages processed. Avg cost:  -1853.3674475097657\n",
      "1000 languages processed. Avg cost:  -1913.6001678466796\n",
      "1050 languages processed. Avg cost:  -2332.329545288086\n",
      "1100 languages processed. Avg cost:  -4569.220536193848\n",
      "1150 languages processed. Avg cost:  -2658.349429626465\n",
      "1200 languages processed. Avg cost:  -2838.766262512207\n",
      "1250 languages processed. Avg cost:  -2278.6818786621093\n",
      "0 languages processed. Avg cost:  -1934.2007555280413\n",
      "50 languages processed. Avg cost:  -2431.9005773925783\n",
      "100 languages processed. Avg cost:  -2048.058779296875\n",
      "150 languages processed. Avg cost:  -1894.0119952392579\n",
      "200 languages processed. Avg cost:  -2200.217657470703\n",
      "250 languages processed. Avg cost:  -2085.7262115478516\n",
      "300 languages processed. Avg cost:  -2815.4133880615236\n",
      "350 languages processed. Avg cost:  -2593.8669885253908\n",
      "400 languages processed. Avg cost:  -2630.945900268555\n",
      "450 languages processed. Avg cost:  -6633.71684753418\n",
      "500 languages processed. Avg cost:  -2599.1863842773437\n",
      "550 languages processed. Avg cost:  -3260.3094940185547\n",
      "600 languages processed. Avg cost:  -2723.1907958984375\n",
      "650 languages processed. Avg cost:  -3093.8629150390625\n",
      "700 languages processed. Avg cost:  -3419.2509143066404\n",
      "750 languages processed. Avg cost:  -4885.887401733398\n",
      "800 languages processed. Avg cost:  -7540.240224609375\n",
      "850 languages processed. Avg cost:  -3562.154705200195\n",
      "900 languages processed. Avg cost:  -3489.1593896484374\n",
      "950 languages processed. Avg cost:  -3171.567682495117\n",
      "1000 languages processed. Avg cost:  -6350.331217041015\n",
      "1050 languages processed. Avg cost:  -2733.4645764160155\n",
      "1100 languages processed. Avg cost:  -3319.711151123047\n",
      "1150 languages processed. Avg cost:  -4326.927669677734\n",
      "1200 languages processed. Avg cost:  -3586.649180908203\n",
      "1250 languages processed. Avg cost:  -9736.606156005859\n",
      "0 languages processed. Avg cost:  -3874.0873434884206\n",
      "50 languages processed. Avg cost:  -3483.982663574219\n",
      "100 languages processed. Avg cost:  -4194.989326171875\n",
      "150 languages processed. Avg cost:  -3298.905607910156\n",
      "200 languages processed. Avg cost:  -4264.644498291015\n",
      "250 languages processed. Avg cost:  -5025.661899414063\n",
      "300 languages processed. Avg cost:  -3728.666663818359\n",
      "350 languages processed. Avg cost:  -5383.727131347656\n",
      "400 languages processed. Avg cost:  -4216.766739501953\n",
      "450 languages processed. Avg cost:  -4469.136022949218\n",
      "500 languages processed. Avg cost:  -4209.362020263672\n",
      "550 languages processed. Avg cost:  -4324.715922851563\n",
      "600 languages processed. Avg cost:  -4914.258172607422\n",
      "650 languages processed. Avg cost:  -4350.830115966797\n",
      "700 languages processed. Avg cost:  -10274.504337158203\n",
      "750 languages processed. Avg cost:  -4057.3481213378905\n",
      "800 languages processed. Avg cost:  -4718.205352783203\n",
      "850 languages processed. Avg cost:  -11271.396267089844\n",
      "900 languages processed. Avg cost:  -5960.844300537109\n",
      "950 languages processed. Avg cost:  -5720.718070068359\n",
      "1000 languages processed. Avg cost:  -15939.670285644532\n",
      "1050 languages processed. Avg cost:  -5448.165190429688\n",
      "1100 languages processed. Avg cost:  -7380.9253442382815\n",
      "1150 languages processed. Avg cost:  -9295.335462646484\n",
      "1200 languages processed. Avg cost:  -5473.577241210937\n",
      "1250 languages processed. Avg cost:  -6394.695595703125\n",
      "0 languages processed. Avg cost:  -5513.423509870257\n",
      "50 languages processed. Avg cost:  -9578.211252441406\n",
      "100 languages processed. Avg cost:  -6352.018239746094\n",
      "150 languages processed. Avg cost:  -6707.117048339844\n",
      "200 languages processed. Avg cost:  -5279.105391845703\n",
      "250 languages processed. Avg cost:  -15760.022944335937\n",
      "300 languages processed. Avg cost:  -6281.071712646484\n",
      "350 languages processed. Avg cost:  -7204.9241235351565\n",
      "400 languages processed. Avg cost:  -15583.772009277343\n",
      "450 languages processed. Avg cost:  -5642.119086914063\n",
      "500 languages processed. Avg cost:  -6898.113059082031\n",
      "550 languages processed. Avg cost:  -5950.457163085937\n",
      "600 languages processed. Avg cost:  -5677.786301269532\n",
      "650 languages processed. Avg cost:  -6937.08283203125\n",
      "700 languages processed. Avg cost:  -9627.742416992187\n",
      "750 languages processed. Avg cost:  -6189.199816894531\n",
      "800 languages processed. Avg cost:  -5183.200771484375\n",
      "850 languages processed. Avg cost:  -6220.617958984375\n",
      "900 languages processed. Avg cost:  -6076.144038085938\n",
      "950 languages processed. Avg cost:  -10965.196481933594\n",
      "1000 languages processed. Avg cost:  -7822.56458984375\n",
      "1050 languages processed. Avg cost:  -5845.948334960937\n",
      "1100 languages processed. Avg cost:  -7819.8475415039065\n",
      "1150 languages processed. Avg cost:  -7448.376651611328\n",
      "1200 languages processed. Avg cost:  -19101.440207519532\n",
      "1250 languages processed. Avg cost:  -11004.417385253906\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "costs = []\n",
    "for e in range(epochs):\n",
    "    for step_num,allophone_data in enumerate(allophone_data_by_language_shuffled()):\n",
    "\n",
    "        allophone_dists   = 0.\n",
    "        nallophone_dists  = 0. \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for allophone_list in allophone_data:\n",
    "            for i,j in distinct_pairs(len(allophone_list)):\n",
    "                allophone_dists += sqdist(emb(allophone_list[i]),emb(allophone_list[j]))\n",
    "        for i,j in distinct_pairs(len(allophone_data)):\n",
    "            for x in allophone_data[i]:\n",
    "                for y in allophone_data[j]:\n",
    "                    nallophone_dists += sqdist(emb(x),emb(y))\n",
    "\n",
    "        cost = allophone_dists - 0.05 * nallophone_dists\n",
    "        cost.backward()\n",
    "        costs.append(cost.item())\n",
    "        if step_num%50==0:\n",
    "            print(step_num,\"languages processed. Avg cost: \",np.mean(costs))\n",
    "            costs = []\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669,  0.1821, -0.1601,  0.1752, -0.1902, -0.1863, -0.0120, -0.1262,\n",
       "          0.1470, -0.0910, -0.1465, -0.1889, -0.1740,  0.1545, -0.1539,  0.1495,\n",
       "          0.1370,  0.1729,  0.1317, -0.0358,  0.1513,  0.0916],\n",
       "        [ 0.1703,  0.1615, -0.1601,  0.1878,  0.1084,  0.1633,  0.1251, -0.1307,\n",
       "          0.1653, -0.1039, -0.0970, -0.2063, -0.1747,  0.1588, -0.0884,  0.1362,\n",
       "          0.2000,  0.1603,  0.1456, -0.0093,  0.1840,  0.1085],\n",
       "        [-0.1747, -0.1669,  0.2123, -0.2316,  0.1628,  0.1897,  0.0788,  0.1241,\n",
       "         -0.1663,  0.1408, -0.0038,  0.1890,  0.1481, -0.1995,  0.1694, -0.1399,\n",
       "         -0.1581, -0.1991, -0.1249,  0.0045, -0.1479, -0.0870],\n",
       "        [ 0.1887,  0.1884, -0.2024,  0.2029,  0.1784,  0.1638, -0.1129,  0.1031,\n",
       "          0.1870, -0.1131, -0.1538, -0.1494, -0.1639,  0.1244, -0.1823,  0.0396,\n",
       "          0.1433,  0.1756,  0.1674, -0.0285,  0.1923,  0.1566],\n",
       "        [-0.2229, -0.2311,  0.2387, -0.1261,  0.1667,  0.1597, -0.1124,  0.1635,\n",
       "         -0.2034,  0.0816,  0.0930,  0.1899,  0.2319, -0.2281, -0.2029, -0.2148,\n",
       "         -0.0058, -0.2532, -0.2103,  0.0154, -0.1532, -0.1907],\n",
       "        [-0.2238, -0.2077,  0.2200, -0.2460,  0.1584,  0.1747, -0.0533,  0.0410,\n",
       "         -0.2155,  0.1442,  0.1059,  0.1987,  0.2159, -0.1860, -0.2169, -0.2006,\n",
       "         -0.1580, -0.2437, -0.2108,  0.0194, -0.1997, -0.1304],\n",
       "        [ 0.2136,  0.1978, -0.1841, -0.0545, -0.1451, -0.2343,  0.1134, -0.1393,\n",
       "          0.1408, -0.1066, -0.1743, -0.1582, -0.2077,  0.2208,  0.1729,  0.1696,\n",
       "          0.0764,  0.1430,  0.1032, -0.0300,  0.1492,  0.0680],\n",
       "        [ 0.2413,  0.2263, -0.2322,  0.2241, -0.1108, -0.2092,  0.0361,  0.0837,\n",
       "          0.2364, -0.0877, -0.2092, -0.1546, -0.2631,  0.2123,  0.1732,  0.2175,\n",
       "          0.2134,  0.2179,  0.2149, -0.0315,  0.2082,  0.1811],\n",
       "        [ 0.1779,  0.1671, -0.1582,  0.1685,  0.0769,  0.1147,  0.1672, -0.1192,\n",
       "          0.1577, -0.0853, -0.1156, -0.0454, -0.1489,  0.0785,  0.2065,  0.1194,\n",
       "          0.1784,  0.1595,  0.1625, -0.0212,  0.1667,  0.1422],\n",
       "        [ 0.1459,  0.1925, -0.1767,  0.1005, -0.1003, -0.2074,  0.1264, -0.1969,\n",
       "          0.1186,  0.0765, -0.1918, -0.1964, -0.2439,  0.1687, -0.2087,  0.2347,\n",
       "          0.1843,  0.2324,  0.1169, -0.0199,  0.2167,  0.1607],\n",
       "        [-0.2250, -0.2096,  0.2404, -0.2346, -0.0403,  0.1947, -0.0338, -0.0121,\n",
       "         -0.2010,  0.0551,  0.1423,  0.1627,  0.2683, -0.2124, -0.1638, -0.2078,\n",
       "         -0.2004, -0.2159, -0.2149,  0.0599, -0.2121, -0.1738],\n",
       "        [-0.2023, -0.1891,  0.2204, -0.1737,  0.0971,  0.1835, -0.0994,  0.1415,\n",
       "         -0.2382,  0.0891, -0.0194,  0.1413,  0.1636, -0.1433,  0.1171, -0.1928,\n",
       "         -0.1476, -0.1661, -0.1927,  0.0294, -0.1933, -0.1236],\n",
       "        [-0.1665, -0.1459,  0.1760, -0.1745,  0.1976,  0.2128, -0.1205, -0.1120,\n",
       "         -0.2087,  0.1054,  0.0296,  0.1864,  0.1589, -0.2032, -0.1946, -0.1981,\n",
       "         -0.1108, -0.1960, -0.1692,  0.0199, -0.1356, -0.1337],\n",
       "        [ 0.2174,  0.2273, -0.2429,  0.2248, -0.1517, -0.1486, -0.0170, -0.0152,\n",
       "          0.2055, -0.1327, -0.1469, -0.1365, -0.2023,  0.1249,  0.1800,  0.1937,\n",
       "          0.1610,  0.2380,  0.1751, -0.0187,  0.1942,  0.1562],\n",
       "        [-0.2117, -0.1897,  0.1848, -0.1833, -0.1659, -0.2205,  0.1327,  0.1460,\n",
       "         -0.2030,  0.0603,  0.1382,  0.1205, -0.1161,  0.1323,  0.1551,  0.0054,\n",
       "         -0.1985, -0.1458,  0.0066, -0.0071, -0.0766, -0.1647],\n",
       "        [ 0.2014,  0.1666, -0.2025,  0.1707,  0.1098, -0.1828,  0.0620, -0.1550,\n",
       "          0.2004, -0.1323, -0.1527, -0.1634, -0.1189,  0.1964, -0.0605,  0.1703,\n",
       "         -0.0493,  0.1531,  0.1656,  0.0232,  0.1291,  0.0859],\n",
       "        [ 0.1903,  0.1797, -0.2292,  0.2265,  0.0922, -0.0878, -0.0339, -0.1429,\n",
       "          0.2099, -0.1290, -0.1693, -0.1886, -0.1949,  0.2021, -0.1671,  0.1061,\n",
       "          0.1552,  0.1771,  0.1946,  0.0006,  0.1542,  0.1197],\n",
       "        [ 0.1883,  0.1633, -0.2015,  0.1857,  0.0297, -0.2141, -0.0274, -0.1357,\n",
       "          0.1948, -0.0972, -0.1494, -0.1639, -0.1780,  0.1989, -0.0753,  0.1365,\n",
       "          0.1533,  0.2010,  0.2099,  0.0196,  0.1711,  0.1753],\n",
       "        [ 0.1830,  0.1997, -0.1649,  0.1675, -0.0969, -0.1755, -0.0034, -0.1535,\n",
       "          0.1634, -0.0865, -0.1792, -0.2297, -0.2068,  0.2015,  0.1554,  0.1404,\n",
       "          0.0456,  0.2023,  0.1386, -0.0313,  0.1545,  0.1092],\n",
       "        [-0.2190, -0.2195,  0.2344, -0.1893,  0.1556,  0.1136, -0.0446,  0.1573,\n",
       "         -0.1932,  0.1263,  0.0296,  0.1993,  0.1872, -0.2055,  0.1378, -0.1708,\n",
       "         -0.1774, -0.2208, -0.2141,  0.0300, -0.2216, -0.1536],\n",
       "        [ 0.2032,  0.2133, -0.2322,  0.1874,  0.0156, -0.2034,  0.0507, -0.1748,\n",
       "          0.1904, -0.0808, -0.1398, -0.2000, -0.1979,  0.2115,  0.0842,  0.2072,\n",
       "          0.1189,  0.2227,  0.1917,  0.0113,  0.1103,  0.1247],\n",
       "        [ 0.1756,  0.1771, -0.2070,  0.2274, -0.0250, -0.1596,  0.0400, -0.1282,\n",
       "          0.1679, -0.1268, -0.1879, -0.1738, -0.2244,  0.1869, -0.0462,  0.2194,\n",
       "          0.1649,  0.2272,  0.1635,  0.0003,  0.1346,  0.1475]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.res.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x,y):\n",
    "    \"\"\"distance between two feature vectors (1d torch tensors) after embedding\"\"\"\n",
    "    return torch.sqrt(sqdist(emb(x),emb(y))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Epitran with language code ind-Latn... success!\n",
      "22.931230545043945 1.3032283782958984\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD91JREFUeJzt3X+MZWV9x/H3pxTRqClQBrLdXTqUblPRxMVMKQlNg2CUH00Wk2LgD90akrXJkmhimq7+oyYlwaRKatKSrIGyNipu/FE2sm2lK8b6h+BAV2BdiVvdsuNudseCCDGl2eXbP+6ZOC7z487cudzZZ96v5Oae85znnPO9J3c/c/LsOeemqpAktes3Rl2AJGm4DHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS435z1AUAXHDBBTU+Pj7qMiTpjPLYY4/9rKrGFuu3KoJ+fHycycnJUZchSWeUJP/dTz+HbiSpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXGr4s5YLc34jgdHtu/Dd944sn1LWh7P6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYtGvRJXpvk0STfT3IgySe69vuS/CTJ/u61uWtPks8kOZTkiSRvG/aHkCTNr5+Hmr0EXFNVLyY5G/hOkn/plv1VVX35tP7XA5u61x8Dd3fvkqQRWPSMvnpe7GbP7l61wCpbgM91630XODfJusFLlSQtR19j9EnOSrIfOAE8VFWPdIvu6IZn7kpyTte2Hjgya/Wprk2SNAJ9BX1VnaqqzcAG4IokbwE+Avwh8EfA+cBfd90z1yZOb0iyLclkksnp6ellFS9JWtySrrqpqp8D3wKuq6pj3fDMS8A/Ald03aaAjbNW2wAcnWNbO6tqoqomxsbGllW8JGlx/Vx1M5bk3G76dcA7gB/OjLsnCXAT8FS3yh7gfd3VN1cCz1fVsaFUL0laVD9X3awDdiU5i94fht1V9fUk30wyRm+oZj/wl13/vcANwCHgl8D7V75sSVK/Fg36qnoCuHyO9mvm6V/A9sFLkyStBO+MlaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGtfPQ800j/EdD466BElalGf0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1btGgT/LaJI8m+X6SA0k+0bVfkuSRJD9K8qUkr+naz+nmD3XLx4f7ESRJC+nnjP4l4JqqeiuwGbguyZXAJ4G7qmoT8BxwW9f/NuC5qvp94K6unyRpRBYN+up5sZs9u3sVcA3w5a59F3BTN72lm6dbfm2SrFjFkqQl6WuMPslZSfYDJ4CHgP8Cfl5VJ7suU8D6bno9cASgW/488NtzbHNbkskkk9PT04N9CknSvPoK+qo6VVWbgQ3AFcCb5urWvc919l6vaKjaWVUTVTUxNjbWb72SpCVa0lU3VfVz4FvAlcC5SWYeirYBONpNTwEbAbrlvwU8uxLFSpKWrp+rbsaSnNtNvw54B3AQeBj4867bVuCBbnpPN0+3/JtV9YozeknSq6OfxxSvA3YlOYveH4bdVfX1JD8A7k/yN8B/Avd0/e8B/inJIXpn8rcMoW5JUp8WDfqqegK4fI72H9Mbrz+9/X+Bm1ekOknSwLwzVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4/r5cfCNSR5OcjDJgSQf7No/nuSnSfZ3rxtmrfORJIeSPJ3kXcP8AJKkhfXz4+AngQ9X1eNJ3gg8luShbtldVfW3szsnuYzeD4K/Gfgd4N+T/EFVnVrJwiVJ/Vn0jL6qjlXV4930C8BBYP0Cq2wB7q+ql6rqJ8Ah5vgRcUnSq2NJY/RJxoHLgUe6ptuTPJHk3iTndW3rgSOzVpti4T8MkqQh6jvok7wB+Arwoar6BXA3cCmwGTgGfGqm6xyr1xzb25ZkMsnk9PT0kguXJPWnr6BPcja9kP98VX0VoKqOV9WpqnoZ+Cy/Gp6ZAjbOWn0DcPT0bVbVzqqaqKqJsbGxQT6DJGkB/Vx1E+Ae4GBVfXpW+7pZ3d4NPNVN7wFuSXJOkkuATcCjK1eyJGkp+rnq5irgvcCTSfZ3bR8Fbk2ymd6wzGHgAwBVdSDJbuAH9K7Y2e4VN5I0OosGfVV9h7nH3fcusM4dwB0D1CVJWiHeGStJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxvXz9EppTRvf8eBI9nv4zhtHsl+1xzN6SWqcZ/Q6I4zqrFpqgWf0ktQ4g16SGmfQS1Lj+vlx8I1JHk5yMMmBJB/s2s9P8lCSH3Xv53XtSfKZJIeSPJHkbcP+EJKk+fVzRn8S+HBVvQm4Etie5DJgB7CvqjYB+7p5gOuBTd1rG3D3ilctSerbokFfVceq6vFu+gXgILAe2ALs6rrtAm7qprcAn6ue7wLnJlm34pVLkvqypDH6JOPA5cAjwEVVdQx6fwyAC7tu64Ejs1ab6tokSSPQd9AneQPwFeBDVfWLhbrO0VZzbG9bkskkk9PT0/2WIUlaor6CPsnZ9EL+81X11a75+MyQTPd+omufAjbOWn0DcPT0bVbVzqqaqKqJsbGx5dYvSVpEP1fdBLgHOFhVn561aA+wtZveCjwwq/193dU3VwLPzwzxSJJeff08AuEq4L3Ak0n2d20fBe4Edie5DXgGuLlbthe4ATgE/BJ4/4pWLElakkWDvqq+w9zj7gDXztG/gO0D1iVJWiHeGStJjTPoJalxBr0kNc6gl6TG+cMjWhJ/AEQ683hGL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjfPOWGmVGtVdyIfvvHEk+9XweEYvSY0z6CWpcQa9JDWunx8HvzfJiSRPzWr7eJKfJtnfvW6YtewjSQ4leTrJu4ZVuCSpP/2c0d8HXDdH+11Vtbl77QVIchlwC/Dmbp1/SHLWShUrSVq6RYO+qr4NPNvn9rYA91fVS1X1E+AQcMUA9UmSBjTIGP3tSZ7ohnbO69rWA0dm9Znq2iRJI7LcoL8buBTYDBwDPtW1Z46+NdcGkmxLMplkcnp6epllSJIWs6ygr6rjVXWqql4GPsuvhmemgI2zum4Ajs6zjZ1VNVFVE2NjY8spQ5LUh2UFfZJ1s2bfDcxckbMHuCXJOUkuATYBjw5WoiRpEIs+AiHJF4GrgQuSTAEfA65OspnesMxh4AMAVXUgyW7gB8BJYHtVnRpO6ZKkfiwa9FV16xzN9yzQ/w7gjkGKkiStHO+MlaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhrXz4+D3wv8GXCiqt7StZ0PfAkYp/fj4O+pqueSBPg74Abgl8BfVNXjwym9Z3zHg8PcvCSd8fo5o78PuO60th3AvqraBOzr5gGuBzZ1r23A3StTpiRpuRYN+qr6NvDsac1bgF3d9C7gplntn6ue7wLnJlm3UsVKkpZuuWP0F1XVMYDu/cKufT1wZFa/qa7tFZJsSzKZZHJ6enqZZUiSFrPS/xmbOdpqro5VtbOqJqpqYmxsbIXLkCTNWG7QH58ZkuneT3TtU8DGWf02AEeXX54kaVDLDfo9wNZueivwwKz296XnSuD5mSEeSdJo9HN55ReBq4ELkkwBHwPuBHYnuQ14Bri5676X3qWVh+hdXvn+IdQsSVqCRYO+qm6dZ9G1c/QtYPugRUmSVs6iQS9pbRnlTYiH77xxZPtumY9AkKTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYN9AtTSQ4DLwCngJNVNZHkfOBLwDhwGHhPVT03WJmSpOVaiTP6t1fV5qqa6OZ3APuqahOwr5uXJI3IMIZutgC7uuldwE1D2IckqU+DBn0B30jyWJJtXdtFVXUMoHu/cMB9SJIGMNAYPXBVVR1NciHwUJIf9rti94dhG8DFF188YBmSpPkMdEZfVUe79xPA14ArgONJ1gF07yfmWXdnVU1U1cTY2NggZUiSFrDsoE/y+iRvnJkG3gk8BewBtnbdtgIPDFqkJGn5Bhm6uQj4WpKZ7Xyhqv41yfeA3UluA54Bbh68TEnSci076Kvqx8Bb52j/H+DaQYqSJK0c74yVpMYZ9JLUOINekho36HX0krRixnc8OJL9Hr7zxpHs99XiGb0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4n3Ujac0b1TN24NV5zo5n9JLUOINekho3tKBPcl2Sp5McSrJjWPuRJC1sKEGf5Czg74HrgcuAW5NcNox9SZIWNqwz+iuAQ1X146r6P+B+YMuQ9iVJWsCwgn49cGTW/FTXJkl6lQ3r8srM0Va/1iHZBmzrZl9M8vSQajnTXAD8bNRFrFIem7l5XOa36o9NPjnQ6r/bT6dhBf0UsHHW/Abg6OwOVbUT2Dmk/Z+xkkxW1cSo61iNPDZz87jMz2PTM6yhm+8Bm5JckuQ1wC3AniHtS5K0gKGc0VfVySS3A/8GnAXcW1UHhrEvSdLChvYIhKraC+wd1vYb5nDW/Dw2c/O4zM9jA6SqFu8lSTpj+QgESWqcQb+KJDmc5Mkk+5NMjrqeUUpyb5ITSZ6a1XZ+koeS/Kh7P2+UNY7CPMfl40l+2n1v9ie5YZQ1jkKSjUkeTnIwyYEkH+za1/x3Bgz61ejtVbXZS8K4D7jutLYdwL6q2gTs6+bXmvt45XEBuKv73mzu/n9srTkJfLiq3gRcCWzvHrvidwaDXqtUVX0bePa05i3Arm56F3DTq1rUKjDPcVnzqupYVT3eTb8AHKR3N/6a/86AQb/aFPCNJI91dw7r111UVceg9w8buHDE9awmtyd5ohvaWZPDEzOSjAOXA4/gdwYw6Febq6rqbfSe+rk9yZ+OuiCdEe4GLgU2A8eAT422nNFJ8gbgK8CHquoXo65ntTDoV5GqOtq9nwC+Ru8poPqV40nWAXTvJ0Zcz6pQVcer6lRVvQx8ljX6vUlyNr2Q/3xVfbVr9juDQb9qJHl9kjfOTAPvBJ5aeK01Zw+wtZveCjwwwlpWjZkg67ybNfi9SRLgHuBgVX161iK/M3jD1KqR5PfoncVD747lL1TVHSMsaaSSfBG4mt7TB48DHwP+GdgNXAw8A9xcVWvqPybnOS5X0xu2KeAw8IGZcem1IsmfAP8BPAm83DV/lN44/Zr+zoBBL0nNc+hGkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1Lj/B2PeMU0EBcb5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wordgen import *\n",
    "wg = WordgenLearned(3,\"ind-Latn\")\n",
    "\n",
    "ipa_chars = wg.load_ipa_chars('eng-Latn')\n",
    "\n",
    "dists = []\n",
    "for c1 in ipa_chars:\n",
    "    for c2 in ipa_chars:\n",
    "        s1,s2 = to_panphon_fts(c1),to_panphon_fts(c2)\n",
    "        assert(len(s1)==1)\n",
    "        assert(len(s2)==1)\n",
    "        s1,s2 = s1[0],s2[0]\n",
    "        if c1 != c2 : dists.append(dist(s1,s2))\n",
    "max_dist,min_dist = max(dists),min(dists)\n",
    "print(max_dist,min_dist)\n",
    "plt.hist(dists)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_chars = list(wg.load_ipa_chars('ind-Latn')) # now this is an ordered list, kind of serving as an enumeration\n",
    "num_chars = len(ipa_chars)\n",
    "projection = [n for n in range(num_chars)] # we start with identity mapping and will gradually identify things\n",
    "# think of projection as mapping from indices representing ipa_chars to equivalence classes\n",
    "# the number of equivalence classes is len(set(projection))\n",
    "M = 25\n",
    "step_size = (max_dist-min_dist)/float((len(ipa_chars)-M)*500)\n",
    "spread = step_size/2.\n",
    "for r0 in np.arange(min_dist,max_dist,step_size):\n",
    "    r = np.random.normal(r0,spread)\n",
    "    ipa_char_index = np.random.randint(num_chars)\n",
    "    s0 = to_panphon_fts(ipa_chars[ipa_char_index])\n",
    "    assert(len(s0)==1)\n",
    "    s0 = s0[0]\n",
    "    for n in range(num_chars):\n",
    "        s = to_panphon_fts(ipa_chars[n])\n",
    "        assert(len(s)==1)\n",
    "        s = s[0]\n",
    "        if dist(s,s0)<r:\n",
    "            projection[n]=projection[ipa_char_index]\n",
    "    if len(set(projection))<=M: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɲ']\n",
      "['r']\n",
      "['b']\n",
      "['ʔ']\n",
      "['w']\n",
      "['ə']\n",
      "['ŋ']\n",
      "['i']\n",
      "['u']\n",
      "['h']\n",
      "['f']\n",
      "['m']\n",
      "['j']\n",
      "['ɡ', 'x']\n",
      "['k']\n",
      "['d']\n",
      "['l']\n",
      "['t͡ɕ', 'd͡ʑ', 'ɕ']\n",
      "['o']\n",
      "['a']\n",
      "['s', 'z']\n",
      "['t']\n",
      "['n']\n",
      "['p']\n"
     ]
    }
   ],
   "source": [
    "for p in set(projection):\n",
    "    print([ipa_chars[n] for n in range(num_chars) if projection[n]==p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: It makes sense that the embedding is cramming together any potential allophones to be really close together, becuase it makes sense to do that and to make up for it by just pushing things more far apart in general. Hmm what do...\n",
    "\n",
    "Basically the issue was that attraction was stronger than repulsion. Strengthening repulsion a bit helped to remedy the problem. The histogram of distances has a spike at small distances, which we could visibly see moving to the right.\n",
    "\n",
    "Next: Run a search, bascially, over different values of that hyperparameter that governs attractions vs repulsion. For each value, show the histogram of distances. Choose the histogram that looks the most \"balanced\" and try that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
