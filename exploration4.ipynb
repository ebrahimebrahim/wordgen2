{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploration3 had confusingly interleaved two separate appraoches. Here we focus on just one, cleaned up quite a bit.\n",
    "\n",
    "We are using phoible to map ipa segments to feature vectors, and then attempting to learn a linear operator on feature space that makes the closeness of feature vectors correspond to the tendency for those segments to be allophones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmbedPhones(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(EmbedPhones, self).__init__()\n",
    "        \n",
    "        self.res = nn.Linear(num_features,num_features,bias=False)\n",
    "#         identity=torch.from_numpy(np.identity(num_features,dtype=np.dtype('float32')))\n",
    "        with torch.no_grad():\n",
    "            self.res.weight.normal_(0,0.02)\n",
    "#             self.embed.weight += identity\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x+self.res(x) # res represents the difference between the embedding map and the identity map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Epitran with language code ind-Latn... success!\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "def add_path_to_local_module(module_name):\n",
    "    module_path = os.path.abspath(os.path.join(module_name))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "add_path_to_local_module(\"epitran\")\n",
    "add_path_to_local_module(\"panphon\")\n",
    "\n",
    "import panphon.featuretable\n",
    "ft = panphon.featuretable.FeatureTable()\n",
    "\n",
    "from wordgen import *\n",
    "wg = WordgenLearned(3,\"ind-Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuppressedMessenger(object):\n",
    "    \"\"\" A class to output messages with output being supressed at a certain point.\"\"\"\n",
    "    def __init__(self,name,max_messages):\n",
    "        self.name = name\n",
    "        self.num_printed = 0\n",
    "        self.max_messages = max_messages\n",
    "        self.stopped_printing = False if max_messages > 0 else True\n",
    "\n",
    "    def print(self,msg):\n",
    "        if self.num_printed < self.max_messages:\n",
    "            print(msg)\n",
    "            self.num_printed += 1\n",
    "        elif not self.stopped_printing:\n",
    "            print(\"[Further output regarding \"+self.name+\" will be suppressed]\")\n",
    "            self.stopped_printing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building mapping from phoible phonemes to feature space...\n",
      "Skipping phoneme ɹ̪̹̩: weird feature label\n",
      "Skipping phoneme ɻ̹̩: weird feature label\n",
      "Skipping phoneme ɹ̪̹̩: weird feature label\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "feat_vals = {'+':1,'-':-1,'0':0}\n",
    "\n",
    "to_phoible_feats_dict = {}\n",
    "\n",
    "f = open('phoible.csv')\n",
    "reader = csv.reader(f)\n",
    "head = next(reader)\n",
    "phoneme_index = head.index('Phoneme')\n",
    "langkey_index = head.index('ISO6393')\n",
    "first_feat_index = head.index('tone')\n",
    "last_feat_index = head.index('click')\n",
    "skipped_msg = SuppressedMessenger(\"bad feature labels\", 10)\n",
    "contradiction_msg = SuppressedMessenger(\"phoible contradictions\", 30)\n",
    "print(\"Building mapping from phoible phonemes to feature space...\")\n",
    "for i,row in enumerate(reader):\n",
    "    phoneme = row[phoneme_index]\n",
    "    raw_feats = row[first_feat_index:last_feat_index+1]\n",
    "#     if any(len(feat)>1 for feat in raw_feats):\n",
    "#         skipped_msg.print(\"Skipping phoneme \"+phoneme+\": multiple feature labels\")\n",
    "    #Instead lets add together multiple feature labels\n",
    "    \n",
    "    try:\n",
    "        feats = np.array([sum(feat_vals[v] for v in val.split(',')) for val in raw_feats],dtype=np.dtype('float32'))\n",
    "    except KeyError:\n",
    "        skipped_msg.print(\"Skipping phoneme \"+phoneme+\": weird feature label\")\n",
    "    if phoneme in to_phoible_feats_dict.keys():\n",
    "        if not np.array_equal(feats,to_phoible_feats_dict[phoneme]):\n",
    "            contradiction_msg.print(\"Phoible contradiction for phoneme \"+phoneme+\"; language \"+row[langkey_index]+\" conflicts w/ prev entry\")\n",
    "    else:\n",
    "        to_phoible_feats_dict[phoneme] = feats\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(to_phoible_feats_dict['a'])\n",
    "len(to_phoible_feats_dict),num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to convert some ipa segs produced by epitran into the representation in phoible\n",
    "epitran_to_phoible_replacements = {\n",
    "    'd͡ʒ':'d̠ʒ',\n",
    "    't͡ʃ':'t̠ʃ',\n",
    "    't͡ɕ':'tɕ',\n",
    "    't͡s':'ts',\n",
    "    'd͡ʑ':'dʑ',\n",
    "}\n",
    "\n",
    "def epitran_to_phoible(epitran_ipa):\n",
    "    phoible_ipa = epitran_ipa\n",
    "    for a,b in epitran_to_phoible_replacements.items():\n",
    "        phoible_ipa = phoible_ipa.replace(a,b)\n",
    "    return phoible_ipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoPhoibleFeatures(Exception):\n",
    "    pass\n",
    "class NoAvailableData(Exception):\n",
    "    pass\n",
    "\n",
    "def to_phoible_fts(ipa_symbols):\n",
    "    \"\"\" Convert a string of ipa symbols to a torch matrix whose rows are features.\n",
    "        Do not include duplicates when panphon identifies symbols in terms of features. \"\"\"\n",
    "    if ipa_symbols == \"NA\" :  raise NoAvailableData(\"The string you gave indicates that there's no allophone data\")\n",
    "    fts=[]\n",
    "    for ft in ipa_symbols.split():\n",
    "        ft = epitran_to_phoible(ft)\n",
    "        try:\n",
    "            fts.append(to_phoible_feats_dict[ft])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if not fts:\n",
    "        raise NoPhoibleFeatures(\"All the phonemes in '\"+ipa_symbols+\"' are giving trouble\")\n",
    "    fts = np.array(fts) \n",
    "    fts = np.unique(fts,axis=0) # do not allow duplicates. TODO: actually you should raise error if you see duplicates; it's not supposed to happen with phoible\n",
    "    fts = fts.astype(np.dtype('float32')) # this is not needed i think, dtype was already set\n",
    "    return torch.from_numpy(fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def allophone_data_by_language(num_lists=np.inf):\n",
    "    f = open('phoible.csv')\n",
    "    reader = csv.reader(f)\n",
    "    head = next(reader)\n",
    "    allophones_index = head.index('Allophones')\n",
    "    langkey_index = head.index('ISO6393')\n",
    "    last_langkey = \"not a lang key\"\n",
    "    num_yielded = 0\n",
    "    for i,row in enumerate(reader):\n",
    "        if row[langkey_index] != last_langkey:\n",
    "#             print(\"About to yield data for language\",last_langkey)\n",
    "            last_langkey = row[langkey_index]\n",
    "            if i!=0 and allophone_data:\n",
    "                yield allophone_data\n",
    "                num_yielded += 1\n",
    "            if num_yielded >= num_lists: break\n",
    "            allophone_data = []\n",
    "        try:\n",
    "            allophone_list = to_phoible_fts(row[allophones_index])\n",
    "        except NoAvailableData: # We will just skip the entire list of allophones in this case\n",
    "            continue\n",
    "        allophone_data.append(allophone_list)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "allophone_data_by_language_list = list(allophone_data_by_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def allophone_data_by_language_shuffled():\n",
    "    indices = list(range(len(allophone_data_by_language_list)))\n",
    "    random.shuffle(indices)\n",
    "    for index in indices:\n",
    "        yield allophone_data_by_language_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_pairs(N):\n",
    "    \"\"\"Generate pairs of integers i<j such that 0 <= i < j < N\"\"\"\n",
    "    for i in range(N):\n",
    "        for j in range(i+1,N):\n",
    "            yield i,j\n",
    "            \n",
    "def sqdist(x,y):\n",
    "    \"\"\"Return squared distance between two 1D torch tensors\"\"\"\n",
    "    return ((x-y)**2).sum()\n",
    "\n",
    "def dist(x,y):\n",
    "    \"\"\"distance between two feature vectors (1d torch tensors) after embedding\"\"\"\n",
    "    return torch.sqrt(sqdist(emb(x),emb(y))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, 1270 languages processed. Avg cost: -614.8590118408204                \r"
     ]
    }
   ],
   "source": [
    "emb = EmbedPhones(num_features)\n",
    "lr = 0.00001\n",
    "alpha = 0.01\n",
    "lambda_ = 1.\n",
    "epochs = 10\n",
    "optimizer = optim.Adam(emb.parameters(),lr=lr,weight_decay=lambda_)\n",
    "\n",
    "costs = []\n",
    "costs_plot = []\n",
    "for e in range(epochs):\n",
    "    for step_num,allophone_data in enumerate(allophone_data_by_language_shuffled()):\n",
    "\n",
    "        allophone_dists   = 0.\n",
    "        nallophone_dists  = 0. \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for allophone_list in allophone_data:\n",
    "            for i,j in distinct_pairs(len(allophone_list)):\n",
    "                allophone_dists += sqdist(emb(allophone_list[i]),emb(allophone_list[j]))\n",
    "        for i,j in distinct_pairs(len(allophone_data)):\n",
    "            for x in allophone_data[i]:\n",
    "                for y in allophone_data[j]:\n",
    "                    nallophone_dists += sqdist(emb(x),emb(y))\n",
    "\n",
    "        cost = allophone_dists - alpha * nallophone_dists\n",
    "        cost.backward()\n",
    "        costs.append(cost.item())\n",
    "        if step_num%10==0:\n",
    "            costs_plot.append(np.mean(costs))\n",
    "            sys.stdout.write(\"Epoch \"+str(e)+\", \"+str(step_num)+\" languages processed. Avg cost: \"+str(np.mean(costs))+\"               \\r\")\n",
    "            sys.stdout.flush()\n",
    "            costs = []\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0455,  0.0232, -0.0622,  ...,  0.0368,  0.0590, -0.0338],\n",
       "        [ 0.0419,  0.0607, -0.0688,  ...,  0.0085,  0.0204, -0.0255],\n",
       "        [-0.0051,  0.0245,  0.0539,  ..., -0.0022,  0.0034,  0.0392],\n",
       "        ...,\n",
       "        [ 0.0566,  0.0329, -0.0225,  ...,  0.0746, -0.0061,  0.0061],\n",
       "        [ 0.0035,  0.0181, -0.0818,  ...,  0.0216,  0.0135, -0.0423],\n",
       "        [ 0.0416, -0.0016,  0.0767,  ...,  0.0408,  0.0717,  0.0507]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.res.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 ['o', 'pʰ', 'ʃ', 'kʼː', 'tː', 't', 'u', 'd͡ʒː', 'æ', 'tʼ', 'i̯', 'ᶑ', 'ɡ', 'ʈʰ', 'ɛ', 'ɣ', 'ɖ', 'ɹ̩', 'd', 'z', 'n̩', 'ɥ', 't͡s', 'd̪', 'l', 'm', 'd͡ʒ', 'kʼ', 'ʋ', 'θ', 'ɲ', 'kʰ', 'f', 'ɡː', 'iː', 'ʊ', 'fː', 'eː', 'j', 'ʒ', 't͡ʃʼː', 'ɭ', 'lː', 'h', 'ð', 't͡ʃʰ', 'n', 'pʼ', 'ɹ', 'hː', 'pː', 't͡ʃʼ', 'ʌ', 'vː', 'i', 'ʉ', 'ɪ', 'm̩', 'sː', 'kː', 'ɳ', 'uː', 'd͡ʑ', 'ŋ', 't͡ɕ', 'q', 'dː', 'e', 'ɑ', 's', 'k', 'a', 'b', 'pʼː', 'ʃː', 'ɦ', 'ə', 'ɕː', 'zː', 'ʎ', 'ɔ', 'tʼː', 'ɘ', 'wː', 'bː', 't̪', 't̪ʰ', 'ɾ', 'oː', 'p', 'v', 'w', 'nː', 'rː', 'jː', 'mː', 'ɲː', 't͡ʃː', 'ɽ', 'ɕ', 'ʁ', 'x', 'aː', 't͡ʃ', 'ʈ', 'r', 'ʔ']\n"
     ]
    }
   ],
   "source": [
    "ipa_charsets = ['eng-Latn','ind-Latn','ita-Latn','kaz-Cyrl','orm-Latn','pan-Guru']\n",
    "ipa_chars = set()\n",
    "for ipa_charset in ipa_charsets:\n",
    "    ipa_chars = ipa_chars.union(wg.load_ipa_chars(ipa_charset))\n",
    "ipa_chars.remove('ː')\n",
    "ipa_chars.remove('̃')\n",
    "ipa_chars = list(ipa_chars)\n",
    "num_chars = len(ipa_chars)\n",
    "print(num_chars,ipa_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha = 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.763212203979492 2.062192440032959\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dists = []\n",
    "for c1 in ipa_chars:\n",
    "    for c2 in ipa_chars:\n",
    "        s1,s2 = to_phoible_fts(c1),to_phoible_fts(c2)\n",
    "        assert(len(s1)==1)\n",
    "        assert(len(s2)==1)\n",
    "        s1,s2 = s1[0],s2[0]\n",
    "        if c1 != c2 : dists.append(dist(s1,s2))\n",
    "max_dist,min_dist = max(dists),min(dists)\n",
    "print(\"\\nalpha =\",alpha)\n",
    "plt.plot(costs_plot)\n",
    "plt.show()\n",
    "print(max_dist,min_dist)\n",
    "plt.hist(dists)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kʼː']\n",
      "['tː', 'ᶑ', 'ɖ', 'd', 'd̪', 'dː', 'ʈ']\n",
      "['ʈʰ']\n",
      "['ɹ̩']\n",
      "['ɥ']\n",
      "['z', 't͡s', 'θ', 'sː', 's']\n",
      "['l', 'ɭ', 'lː', 'ɽ']\n",
      "['kʼ']\n",
      "['ʋ']\n",
      "['ɲ', 'ɲː']\n",
      "['ɡ', 'kʰ', 'ɡː', 'kː', 'k']\n",
      "['j', 'jː']\n",
      "['t͡ʃʰ', 't͡ʃ']\n",
      "['n̩', 'n', 'ɳ', 'nː']\n",
      "['ɹ']\n",
      "['hː']\n",
      "['t͡ʃʼː', 't͡ʃʼ']\n",
      "['f', 'fː', 'vː', 'v']\n",
      "['ð', 'd͡ʑ', 't͡ɕ']\n",
      "['ŋ']\n",
      "['q']\n",
      "['æ', 'i̯', 'ɛ', 'iː', 'eː', 'i', 'ɪ', 'e', 'a', 'ə', 'ɘ']\n",
      "['ʌ', 'ɑ', 'aː']\n",
      "['pʼ', 'pʼː']\n",
      "['ʃ', 'd͡ʒː', 'd͡ʒ', 'ʒ', 'ʃː', 't͡ʃː']\n",
      "['h', 'ɦ']\n",
      "['ɕː', 'ɕ']\n",
      "['zː']\n",
      "['ʎ']\n",
      "['tʼ', 'tʼː']\n",
      "['wː', 'w']\n",
      "['t', 't̪', 't̪ʰ']\n",
      "['o', 'u', 'ʊ', 'ʉ', 'uː', 'ɔ', 'oː']\n",
      "['pʰ', 'pː', 'b', 'bː', 'p']\n",
      "['rː']\n",
      "['m', 'm̩', 'mː']\n",
      "['ɾ']\n",
      "['ɣ', 'ʁ', 'x']\n",
      "['r']\n",
      "['ʔ']\n"
     ]
    }
   ],
   "source": [
    "projection = [n for n in range(num_chars)] # we start with identity mapping and will gradually identify things\n",
    "# think of projection as mapping from indices representing ipa_chars to equivalence classes\n",
    "# the number of equivalence classes is len(set(projection))\n",
    "M = 40\n",
    "step_size = (max_dist-min_dist)/float((len(ipa_chars)-M)*500)\n",
    "spread = (max_dist-min_dist)/20.\n",
    "for r0 in np.arange(min_dist,max_dist,step_size):\n",
    "    r = max(step_size,np.random.normal(r0,spread))\n",
    "    ipa_char_index = np.random.randint(num_chars)\n",
    "    s0 = to_phoible_fts(ipa_chars[ipa_char_index])\n",
    "    assert(len(s0)==1)\n",
    "    s0 = s0[0]\n",
    "    for n in range(num_chars):\n",
    "        s = to_phoible_fts(ipa_chars[n])\n",
    "        assert(len(s)==1)\n",
    "        s = s[0]\n",
    "        if dist(s,s0)<r:\n",
    "            projection[n]=projection[ipa_char_index]\n",
    "    if len(set(projection))<=M: break\n",
    "        \n",
    "for p in set(projection):\n",
    "    print([ipa_chars[n] for n in range(num_chars) if projection[n]==p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay let's assume this works and look into the problem of choosing a representative from each equivalence class.\n",
    "\n",
    "Initital idea: Choose a random direction in feature space (post-emb feature space, I think), and always pick the representative that is most in that direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = np.array([np.random.normal() for _ in range(num_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kʼː ['kʼː']\n",
      "ɖ ['tː', 'ᶑ', 'ɖ', 'd', 'd̪', 'dː', 'ʈ']\n",
      "ʈʰ ['ʈʰ']\n",
      "ɹ̩ ['ɹ̩']\n",
      "ɥ ['ɥ']\n",
      "t͡s ['z', 't͡s', 'θ', 'sː', 's']\n",
      "ɽ ['l', 'ɭ', 'lː', 'ɽ']\n",
      "kʼ ['kʼ']\n",
      "ʋ ['ʋ']\n",
      "ɲ ['ɲ', 'ɲː']\n",
      "ɡ ['ɡ', 'kʰ', 'ɡː', 'kː', 'k']\n",
      "j ['j', 'jː']\n",
      "t͡ʃ ['t͡ʃʰ', 't͡ʃ']\n",
      "n̩ ['n̩', 'n', 'ɳ', 'nː']\n",
      "ɹ ['ɹ']\n",
      "hː ['hː']\n",
      "t͡ʃʼ ['t͡ʃʼː', 't͡ʃʼ']\n",
      "v ['f', 'fː', 'vː', 'v']\n",
      "ð ['ð', 'd͡ʑ', 't͡ɕ']\n",
      "ŋ ['ŋ']\n",
      "q ['q']\n",
      "a ['æ', 'i̯', 'ɛ', 'iː', 'eː', 'i', 'ɪ', 'e', 'a', 'ə', 'ɘ']\n",
      "aː ['ʌ', 'ɑ', 'aː']\n",
      "pʼ ['pʼ', 'pʼː']\n",
      "d͡ʒ ['ʃ', 'd͡ʒː', 'd͡ʒ', 'ʒ', 'ʃː', 't͡ʃː']\n",
      "ɦ ['h', 'ɦ']\n",
      "ɕ ['ɕː', 'ɕ']\n",
      "zː ['zː']\n",
      "ʎ ['ʎ']\n",
      "tʼ ['tʼ', 'tʼː']\n",
      "w ['wː', 'w']\n",
      "t ['t', 't̪', 't̪ʰ']\n",
      "ʊ ['o', 'u', 'ʊ', 'ʉ', 'uː', 'ɔ', 'oː']\n",
      "b ['pʰ', 'pː', 'b', 'bː', 'p']\n",
      "rː ['rː']\n",
      "m̩ ['m', 'm̩', 'mː']\n",
      "ɾ ['ɾ']\n",
      "ɣ ['ɣ', 'ʁ', 'x']\n",
      "r ['r']\n",
      "ʔ ['ʔ']\n"
     ]
    }
   ],
   "source": [
    "section = {} # Think of section as a map back from the codomain of projection to the domain which picks a rep of each equivalence class\n",
    "for p in set(projection):\n",
    "    equiv_class = [n for n in range(num_chars) if projection[n]==p]\n",
    "    rep = max(equiv_class,key=lambda n : np.dot(to_phoible_fts(ipa_chars[n]).numpy(),direction).item())\n",
    "    for n in equiv_class: section[n] = rep\n",
    "    print(ipa_chars[rep],[ipa_chars[n] for n in equiv_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_eng = load_wg('en10e4.pkl')\n",
    "wg_ind = load_wg('id10e5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t͡ɕ ['t͡ɕ']\n",
      "d͡ʒ ['ʃ', 't͡ʃ', 'd͡ʒ']\n",
      "u ['o', 'u', 'ʊ']\n",
      "i ['e', 'æ', 'ɛ', 'ə', 'i', 'ɪ']\n",
      "ɑ ['ɑ', 'a']\n",
      "ɡ ['k', 'ɡ']\n",
      "s ['s']\n",
      "d ['t', 'd']\n",
      "n̩ ['n̩']\n",
      "l ['l']\n",
      "ɔ ['ɔ']\n",
      "ɲ ['ɲ']\n",
      "v ['f', 'v']\n",
      "ɾ ['ɾ']\n",
      "b ['b', 'p']\n",
      "j ['j']\n",
      "w ['w']\n",
      "h ['h']\n",
      "ʒ ['z', 'd͡ʑ', 'θ', 'ʒ', 'ð']\n",
      "n ['n']\n",
      "ɹ ['ɹ̩', 'ɹ']\n",
      "ɕ ['ɕ']\n",
      "ʌ ['ʌ']\n",
      "x ['x']\n",
      "m ['m', 'm̩']\n",
      "ŋ ['ŋ']\n",
      "r ['r']\n",
      "ʔ ['ʔ']\n"
     ]
    }
   ],
   "source": [
    "# These are the learned wordgen objects to be merged\n",
    "learned_gens = [wg_eng,wg_ind]\n",
    "\n",
    "# First gather all ipa_tokens\n",
    "all_ipa_tokens = set()\n",
    "for gen in learned_gens:\n",
    "    all_ipa_tokens.update(gen.get_ipa_tokens())\n",
    "    \n",
    "# Remove any bad tokens that phoible won't like for the next part. If these are there then they're dumb anyway.\n",
    "# We will also remove the start and end tokens; they will be brought back in later\n",
    "bad_tokens = ['ː','̃','WORD_START','WORD_END']\n",
    "for t in bad_tokens: \n",
    "    if t in all_ipa_tokens: \n",
    "        all_ipa_tokens.remove(t)\n",
    "        \n",
    "# Compute max and min distances tokens have from each other via the feature embedding\n",
    "all_ipa_tokens = list(all_ipa_tokens)\n",
    "num_all_tokens = len(all_ipa_tokens)\n",
    "dists = []\n",
    "for c1 in all_ipa_tokens:\n",
    "    for c2 in all_ipa_tokens:\n",
    "        s1,s2 = to_phoible_fts(c1),to_phoible_fts(c2)\n",
    "        assert(len(s1)==1)\n",
    "        assert(len(s2)==1)\n",
    "        s1,s2 = s1[0],s2[0]\n",
    "        if c1 != c2 : dists.append(dist(s1,s2))\n",
    "max_dist,min_dist = max(dists),min(dists)\n",
    "\n",
    "# Create equivalence classes of phonemes to cut down number of sounds\n",
    "projection = [n for n in range(num_all_tokens)] # we start with identity mapping and will gradually identify things\n",
    "# think of projection as mapping from indices representing ipa_chars to equivalence classes\n",
    "# the number of equivalence classes is len(set(projection))\n",
    "M = int(np.random.normal(35,10)) # choose number of sounds\n",
    "step_size = (max_dist-min_dist)/float((num_all_tokens-M)*500)\n",
    "spread = (max_dist-min_dist)/20.\n",
    "for r0 in np.arange(min_dist,max_dist,step_size):\n",
    "    r = max(step_size,np.random.normal(r0,spread))\n",
    "    ipa_char_index = np.random.randint(num_all_tokens)\n",
    "    s0 = to_phoible_fts(all_ipa_tokens[ipa_char_index])\n",
    "    assert(len(s0)==1)\n",
    "    s0 = s0[0]\n",
    "    for n in range(num_all_tokens):\n",
    "        s = to_phoible_fts(all_ipa_tokens[n])\n",
    "        assert(len(s)==1)\n",
    "        s = s[0]\n",
    "        if dist(s,s0)<r:\n",
    "            projection[n]=projection[ipa_char_index]\n",
    "    if len(set(projection))<=M: break\n",
    "\n",
    "# Choose a representative for each equivalence class to serve as the standard/official pronunciation for the new language\n",
    "direction = np.array([np.random.normal() for _ in range(num_features)])\n",
    "section = {} # Think of section as a map back from the codomain of projection to the domain which picks a rep of each equivalence class\n",
    "for p in set(projection):\n",
    "    equiv_class = [n for n in range(num_all_tokens) if projection[n]==p]\n",
    "    rep = max(equiv_class,key=lambda n : np.dot(to_phoible_fts(all_ipa_tokens[n]).numpy(),direction).item())\n",
    "    for n in equiv_class: section[n] = rep\n",
    "    print(all_ipa_tokens[rep],[all_ipa_tokens[n] for n in equiv_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t͡ɕ': ['t͡ɕ'],\n",
       " 'u': ['o', 'u', 'ʊ'],\n",
       " 'ɑ': ['ɑ', 'a'],\n",
       " 'ɡ': ['k', 'ɡ'],\n",
       " 'b': ['b', 'p'],\n",
       " 's': ['s'],\n",
       " 'd': ['t', 'd'],\n",
       " 'n̩': ['n̩'],\n",
       " 'l': ['l'],\n",
       " 'ɔ': ['ɔ'],\n",
       " 'm': ['m', 'm̩'],\n",
       " 'd͡ʒ': ['ʃ', 't͡ʃ', 'd͡ʒ'],\n",
       " 'ɲ': ['ɲ'],\n",
       " 'ɾ': ['ɾ'],\n",
       " 'v': ['f', 'v'],\n",
       " 'j': ['j'],\n",
       " 'w': ['w'],\n",
       " 'ʒ': ['z', 'd͡ʑ', 'θ', 'ʒ', 'ð'],\n",
       " 'h': ['h'],\n",
       " 'n': ['n'],\n",
       " 'ɹ': ['ɹ̩', 'ɹ'],\n",
       " 'ɕ': ['ɕ'],\n",
       " 'ʌ': ['ʌ'],\n",
       " 'x': ['x'],\n",
       " 'i': ['e', 'æ', 'ɛ', 'ə', 'i', 'ɪ'],\n",
       " 'ŋ': ['ŋ'],\n",
       " 'r': ['r'],\n",
       " 'ʔ': ['ʔ'],\n",
       " 'WORD_START': ['WORD_START'],\n",
       " 'WORD_END': ['WORD_END']}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actually it will be more useful here to have a mapping from ipa tokens representing an equiv class to the rest of the equiv class\n",
    "token_to_equivclass = {}\n",
    "for rep_index in set(section.values()):\n",
    "    equiv_class_indices = [n for n in range(num_all_tokens) if projection[n]==projection[rep_index]]\n",
    "    equiv_class_tokens = [all_ipa_tokens[n] for n in equiv_class_indices]\n",
    "    token_to_equivclass[all_ipa_tokens[rep_index]] = equiv_class_tokens\n",
    "token_to_equivclass['WORD_START']=['WORD_START']\n",
    "token_to_equivclass['WORD_END']=['WORD_END']\n",
    "token_to_equivclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_tokens = list(token_to_equivclass.keys())\n",
    "num_tokens = len(ipa_tokens)\n",
    "int_to_token = {n:ipa_tokens[n] for n in range(num_tokens)}\n",
    "ipa_tokens = set(ipa_tokens)\n",
    "token_to_int = {val:key for key,val in int_to_token.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = wg_eng.window_size\n",
    "# should really do a check that all languages have same window size\n",
    "# or maybe you should make window size be min over all languages, printing warning for this\n",
    "\n",
    "distribution = np.zeros((num_tokens,)*window_size,dtype=np.dtype('float32'))\n",
    "distribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be non-empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-257-60246dee5b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mk_corresponding_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_to_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk_corresponding_token\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearned_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipa_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if that won't do, then...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mk_corresponding_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_equiv_class\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearned_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipa_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mk_corresponding_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearned_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_corresponding_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be non-empty"
     ]
    }
   ],
   "source": [
    "# NOTE: This was a dumb idea. Skip this cell.\n",
    "\n",
    "# First I will assume window_size is 3. But soon come up with recursive approach that doesn't.\n",
    "for i in range(num_tokens):\n",
    "    i_equiv_class = token_to_equivclass[int_to_token[i]] # list of equivalent IPA tokens\n",
    "    learned_gen = np.random.choice([gen for gen in learned_gens if any(t in gen.get_ipa_tokens() for t in i_equiv_class)])\n",
    "    learned_distribution = learned_gen.get_distribution()\n",
    "    i_corresponding_token = int_to_token[i] # first we will try using this very token\n",
    "    if i_corresponding_token not in learned_gen.get_ipa_tokens(): # if that won't do, then...\n",
    "        i_corresponding_token = np.random.choice([t for t in i_equiv_class if t in learned_gen.get_ipa_tokens()])\n",
    "    i_corresponding_index = learned_gen.token_to_int(i_corresponding_token)\n",
    "    for j in range(num_tokens):\n",
    "        j_equiv_class = token_to_equivclass[int_to_token[j]] # list of equivalent IPA tokens\n",
    "        j_corresponding_token = int_to_token[j]\n",
    "        if j_corresponding_token not in learned_gen.get_ipa_tokens(): # if that won't do, then...\n",
    "            j_corresponding_token = np.random.choice([t for t in j_equiv_class if t in learned_gen.get_ipa_tokens()])\n",
    "        j_corresponding_index = learned_gen.token_to_int(j_corresponding_token)\n",
    "        for k in range(num_tokens):\n",
    "            k_equiv_class = token_to_equivclass[int_to_token[k]] # list of equivalent IPA tokens\n",
    "            k_corresponding_token = int_to_token[k]\n",
    "            if k_corresponding_token not in learned_gen.get_ipa_tokens(): # if that won't do, then...\n",
    "                k_corresponding_token = np.random.choice([t for t in k_equiv_class if t in learned_gen.get_ipa_tokens()])\n",
    "            k_corresponding_index = learned_gen.token_to_int(k_corresponding_token)\n",
    "            \n",
    "            distribution[i,j,k] = learned_distribution[i_corresponding_index,j_corresponding_index,k_corresponding_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "distribution = np.zeros((num_tokens,)*window_size,dtype=np.dtype('float32'))\n",
    "for token_indices in product(range(num_tokens),repeat=window_size):\n",
    "    \n",
    "    tokens = [int_to_token[i] for i in token_indices]\n",
    "    equiv_classes = [token_to_equivclass[t] for t in tokens]\n",
    "    \n",
    "    potential_gens = {} # keys will be learned wordgens that could be used to populate distribution[token_indices]\n",
    "                        # values will be a score; higher means better candidate\n",
    "    for gen in learned_gens:\n",
    "        potential_tokens = gen.get_ipa_tokens()\n",
    "        if all(any(t in potential_tokens for t in cls) for cls in equiv_classes):\n",
    "            potential_gens[gen] = sum(1 for t in tokens if t in potential_tokens)\n",
    "    \n",
    "    if not potential_gens: # if it's an empty dict\n",
    "        continue # move on and leave distribution[token_indices] as zero\n",
    "    \n",
    "    max_score = max(potential_gens.values())\n",
    "    best_gens = [gen for gen in potential_gens.keys() if potential_gens[gen]==max_score]\n",
    "    gen_to_use = np.random.choice(best_gens)\n",
    "    \n",
    "    indices_to_use = [] # indices of gen_to_use type to use for each token in tokens\n",
    "    for t in tokens:\n",
    "        if t in gen_to_use.get_ipa_tokens():\n",
    "            indices_to_use.append(gen_to_use.token_to_int(t))\n",
    "        else:\n",
    "            potential_indices = [gen_to_use.token_to_int(t1) for t1 in token_to_equivclass[t] if t1 in gen_to_use.get_ipa_tokens()]\n",
    "            indices_to_use.append(np.random.choice(potential_indices))\n",
    "    indices_to_use = tuple(indices_to_use)\n",
    "    \n",
    "    distribution[token_indices] = gen_to_use.get_distribution()[indices_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-normalize distribution\n",
    "totals = distribution.sum(axis=window_size-1)\n",
    "distribution = distribution / (np.vectorize(lambda x : x if x!=0 else 1)(totals.reshape(totals.shape+(1,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Epitran with language code eng-Latn... success!\n"
     ]
    }
   ],
   "source": [
    "# A bad temporary approach here until I make an actual class WordgenGenerated\n",
    "wg = WordgenLearned(window_size,'eng-Latn') # the eng-Latn is just to not have error. We will get rid of it what it does.\n",
    "wg._ipa_tokens = ipa_tokens\n",
    "wg._int_to_token = int_to_token\n",
    "wg._token_to_int = token_to_int\n",
    "wg._distribution = distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɡrɑsɑns\n",
      "hɑɹd͡ʒ\n",
      "Uh oh! This shouldn't happen, right? [11, 10]\n",
      "bʌd͡ʒmw\n",
      "lurʔɑxirum\n",
      "ɡɹul\n",
      "t͡ɕhɑɹd͡ʒ\n",
      "ɔɹɡjundi\n",
      "ɹid͡ʒi\n",
      "blibɹi\n",
      "rindi\n",
      "bɔlsurumlisiv\n",
      "biliŋ\n",
      "judisi\n",
      "liɑliŋ\n",
      "budrɑs\n",
      "ɑɹɡjuruvd\n",
      "hɔɹi\n",
      "swɑrludusi\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    word = wg.generate_word()\n",
    "    if len(word)>3:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh... what happened there? Look into that. Then create a class that does this stuff, then collect lots of learned languages and try out a merging!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
